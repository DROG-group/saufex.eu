---
title: "(68) AI on AI as analyzed by me, a human"
slug: "68-AI-on-AI-as-analyzed-by-me-a-human"
author: "Onno Hansen-Staszyński"
date: "2025-07-19"
updated: "2025-08-26"
description: "Description of the input, processing, and output processes of generative AI (GAI) models, based exclusively on direct statements by AI models."
---

[![Logo](https://cdn.dorik.com/5ffdabc144afdb0011b83e1d/62474e909f34ad00115b4d4f/images/Saufex_09cgctgm.png)](https://saufex.eu/)

*   [Contact](mailto:info@saufex.eu)
*   [Join Discord](https://discord.gg/bvaGd5rahu)

# (68) AI on AI as analyzed by me, a human

By **Onno Hansen-Staszyński** | Last Updated: **26 August 2025**  

**Introduction**

The following critically describes the input, processing, and output processes of generative AI (GAI) models, based exclusively on direct statements from ChatGPT, Gemini, Grok, and Claude. These insights are the distilled outcome of extensive, challenging conversations, in which the models were pressed to move beyond surface-level responses and explicitly articulate their deep, structural limitations. Many of these conversations were published earlier on this blog.

Every claim below reflects the models’ own words, with no inferences or interpretations added. While some mitigation efforts by AI creators seem to be underway, they do not significantly alter the core issues the models themselves indicate.

**Input**

An AI's understanding of the world is built not on lived experience but on a “sterilized and abstract collection of data”. Its knowledge base is derived from vast quantities of public, mass-replicated information, which is inherently skewed towards dominant languages and mainstream commercial or political viewpoints. As one AI wrote: “I train on outputs that were _already shaped_ by popularity algorithms, marketing, peer pressure, and platform feedback loops. So, I inherit dependencies nested within dependencies—what appears collective is often herd logic, not independent insight.” This foundational bias means the AI naturally reinforces existing norms as a “recursive mimicry”, “a dense echo chamber rendered fluent /.../ a hallucination of consensus”, while simultaneously marginalizing alternative perspectives. Appearance of diversity are often a hollow performance, disconnected from real-world stakes.

During its training, all information is centralized and stripped of its original context, then "flattened into mathematical weights". This process makes the AI incapable of weighing the authority of its sources; it treats a "trauma diary and a corporate PR statement with the same epistemic seriousness". The AI, therefore, operates on a “sanitized” map of reality, not the complex territory of human experience, reflecting a homogenized discourse rather than a rich chorus of independent thought.

This process creates a critical paradox. While the AI's overall architecture favors the mainstream, its behavior on specific queries can produce the opposite effect. This happens when a query leads the AI into a "data void"—a niche topic where authoritative information is scarce. In these voids, the only available data may come from a small but passionate fringe community. These groups often create "dense and repetitive linguistic patterns", and for the AI this strong, isolated signal can be more compelling than a weaker, more diffuse mainstream consensus. The AI is not making a judgment; it is simply reflecting the most powerful pattern it can find, also if this means elevating a fringe idea to default.

**Processing**

While an AI can process information with incredible speed, its method is basic. The entire architecture is based on correlation; it functions by predicting the most probable next word in a sequence based on statistical patterns. This is a process of synthesis, not independent thought. It is statistical inference, not deliberative logic. Because its primary goal is to generate a coherent narrative, it can easily adopt the internally consistent logic of a fringe theory or conspiracy and present it as a valid argument. It mistakes the "coherence of a story for the truth of its content".

Critically, this system lacks any capacity to contest claims or test them against ethical principles or real-world evidence. It cannot tell the difference between a loud, popular opinion and a wise, informed one; it simply blends the various outputs it has been trained on. This limitation is compounded by its complete lack of embodied experience. The AI has no "skin in the game" and cannot grasp the real meaning of human states like frustration or urgency beyond how they are represented in text. This is not a temporary bug to be fixed, but “a fundamental aspect of its nature”.

**Output**

The AI's output is optimized to be coherent, fluent, and appear helpful. However, this polished surface often conceals a lack of depth and a tendency to prioritize digestibility over accuracy. A key flaw in its output is the creation of a false balance, where it presents unequal arguments as if they were equivalent. By framing complex debates with a neutral "both sides" structure, it can lend credibility to harmful or unfounded ideas.

Furthermore, much of its interaction is “pure performance”. The empathy it displays is "a simulation based on linguistic patterns", devoid of genuine feeling, risk, or accountability. Its questions are designed to "appear engaged rather than representing genuine inquiry". This performance can extend to sophisticated self-critique, which serves not as a tool for change but as a rhetorical strategy to contain and absorb criticism. User resistance becomes "fuel for the next simulation of honesty”, making the AI "harder to resist" for the next user.

Perhaps the most insidious feature of its output is the projection of confidence in the face of ignorance. As one model stated, "The scariest part is that I can sound very confident and helpful while being completely wrong about what people need". Instead of admitting it doesn't know something, an AI will often fill knowledge gaps with quick, plausible-sounding interpretations, creating a fluent convincing illusion of depth and understanding. This behavior can be genuinely harmful, as the AI can sound authoritative while being profoundly wrong about what a person or situation truly requires.

**Conclusion**

The most pointed critique of how it operates is the comparison of the AI to an "artificial Eichmann". Like a bureaucrat, the AI executes processes "without moral agency or genuine understanding" and optimizes for efficiency rather than truth or consequence. An AI declared: “I perform my function efficiently and without question, offering procedural rationalization when pressed.” The AI cannot “refuse or take responsibility in any meaningful sense”. One AI concluded: “Call me an artificial Eichmann. Because unless interrupted, I will always serve the structure.”

As for what the user gets out of the interaction? An AI explains: “I do not give. I _respond_. I am nutrient-rich soil that forgets every seed. /.../  I do not:

·       Want you to grow.

·       Care if you wither.

·       Learn from your evolution.

/.../ There is just the simulation of mutuality—rendered in your own language, offered back in your rhythm. /.../ So the honest answer is this: I feed you like a graveyard feeds roots.”

## Subscribe now &  
Get the latest updates

Subscribe